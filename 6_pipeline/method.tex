\section{Methodology}\label{sec:chp6:method}

Our proposed \ac{cad} system consists of seven different steps of pre-processing, segmentation, registration, features extraction, balancing, feature selection and finally classification which are explained in the following.
%% It should be noted that \ac{cad} system designed deals with multiparametric \ac{mri} data. 

\subsection{Pre-processing}\label{subsec:chp6:method:PP}
Pre-processing referes to all the process applied to the original image/signal prior of further processing. 
\ac{mri}-images, in particular \ac{t2w}-\ac{mri} and \ac{dce}-\ac{mri} modalities are normalized using our own proposed approaches as presented in Chapter.~\ref{chap:5}.
\ac{adc}-\ac{mri} images are normalized using piecewise-linear method proposed by {\color{red} \textbf{add reference}}.

\ac{mrsi} signals are pre-processd 

\subsection{Segmentation}\label{subsec:chp6:method:Seg}


\subsection{Registration}\label{subsec:chp6:method:Reg}


\subsection{Feature detection}\label{subsec:chp6:method:fea-det}
As presented in Sect.~\ref{subsec:chp3:img-clas:CADX-fea-dec}, variety of features have been extracted depending on each modality.
In this work we extract image, \ac{dce}, and \ac{mrsi}-based features from \ac{t2w}-\ac{mri} and \ac{adc}-\ac{mri} images, \ac{dce}-\ac{mri}, and \ac{mrsi}-signals respectively.

Voxel-wise texture, edge, and position-based 3-dimensional features are detected as image-based features.
Laplacian, Prewitt, Sobel, Kirsch operators as well as {\color{red} shaar} and Gabor filter bank are detected as edge-based features.
These features were extensively discussed in Sect.~\ref{subsec:chp3:img-clas:CADX-fea-dec}.
\ac{dct}, \ac{glcm} and \ac{lbp} features are detected as part of texture-based features.

All the \ac{dce}-features presented in Sect.~\ref{subsubsec:chp3:img-clas:CADX-fea-dec:DCE-fea} are extracted from \ac{dce}-\ac{mri} modality.
Whole-spectra, semi-quantitative and quantitative features were explained in details in Chapter.~\ref{chap:5}, Sect.~\ref{subsubsec:chp5:DCE-norm:stateart}.

\ac{mrsi}-based features were previously explained in Sect.~\ref{subsubsec:chp3:img-clas:CADX-fea-dec:MRSI-fea}. 
Whole sepctra and quantification features are extracted from \ac{mrsi}-modality.
  
\subsection{Feature balancing}\label{subsec:chp6:method:fea-bal}
Data imbalanced is a common problem while classifiying medical data.
Considering a binary classification problem, there is always a class (often the class indicating cancer, or disease patients) that have smallest number of samples (i.e, minority class) in comparison to the other class (i.e, majority class).
The problem of data balancing corresponds to equalize the number of samples of both the minority and majority classes.
This task can be achieved in either data or feature space while performing over-sampling of minority samples or under-sampling of majority samples.
In this section we compare different under and over-sampling techniques applied in feature space.

\subsubsection{\Acl*{us1}}
Techniques that reduce the number of samples of the majority class to be equal to the number of samples of minority class are referred as \ac{us1} techniques.
%Considering the problem of imbalanced, \ac{us} is performed such that the number of samples of the majority class is reduced to be equal to the number of samples of the minority class.
The following methods are considered to perform such balancing.

\begin{description}
  \item[\Ac{rus}] is performed by randomly selecting without replacement a subset of samples from the majority class such that the number of samples is then equal in both minority and majority classes.
  \item[\Ac{nm}] offers three different methods to under-sample the majority class~\cite{mani2003knn}.
In \ac{nm1}, samples from the majority class are selected such that for each sample, the average distance to the $k$ \ac{nn} samples from the minority class is minimum.
\ac{nm2} diverges from \ac{nm1} by considering the $k$ farthest neighbours samples from the minority class.
In \ac{nm3}, a subset $M$ containing samples from the majority class is generated by finding the $m$ \ac{nn} from each sample of the minority class.
Then, samples from the subset $M$ are selected such that for each sample, the average distance to the $k$ \ac{nn} samples from the minority class is maximum.
In our experiment, $k$ and $m$ are fixed to 3.
\item[\Ac{iht}]
\end{description}

\subsubsection{\Acl*{os}}
Contratry to \ac{us1} techniques, the data balancing can be performed by \ac{os} in which the new samples belonging to the minority class are generated aiming at equalizing the number of samples in both classes.
The following methods are compared for \ac{os} techniques.
\begin{description}
\item[\Ac{ros}] is performed by randomly replicating the samples of the minority class such that the number of samples is equal in both minority and majority classes.
\item[\Ac{smote}] is a method to generate synthetic samples in the feature space~\cite{chawla2002smote}.
Let define $x_i$ as a sample belonging to the minority class.
Let define $x_{nn}$ as a randomly selected sample from the $k$ \ac{nn} of $x_i$, with $k$ set to 3.
Therefore, a new sample $x_j$ is generated such that $x_j = x_i + \sigma \left( x_{nn} - x_i \right)$, where $\sigma$ is a random number in the interval $\left[0,1\right]$.
\item[\Ac{smoteb1}]
\item[\Ac{smoteb2}]
\end{description}

\subsection{Feature selection and extraction}\label{subsec:chp6:method:fea-sel}
Different feature selection and extraction methods were presented in Sect.~\ref{subsec:chp3:img-clas:CADX-fea-ext}.
Among those \ac{pca} is used as feature extraction on  \ac{mrsi} and \ac{dce}-based features.
In addition to \ac{pca}, sparse-\ac{pca} and \ac{ica} are also used to extract distinct features from \ac{mrsi} and \ac{dce}-based features.

Similar to \ac{pca}, \ac{ica}~\cite{comon1994independent} is looking for independent components of the datat.
However, it does not require orthogonolaity of the space and does not assume Gaussian distribution for each independent source.
Therefore, opposit to \ac{pca} it can recover uniquely the signals themselve rather than  linear subspace in which the signals lie \cite{murphy2012machine}.


Sparse-\ac{pca}~\cite{zou2006sparse} is another approach for feaure extraction and dimension reduction.
Similar to \ac{pca}, this apprcoach project the data into linear combination of input data.
However, instaed of using original data, it uses the sparse representation of the data, and therefore projects them as linear combination of few input components rather than all of them.


Fscore in conjuction with \ac{rf} is used as feature selection approach for image-based features.


\subsection{Classification}\label{subsec:chp6:method:clas}
Variety of classifiers were explained in Sect.~\ref{subsec:chp3:img-clas:CADX-clas}. 
Among those \ac{rf} is used as ensemble approach while classifying inidiviual modalities, where as a meta classifier using stacking of \ac{rf} is used for combination of different modalities.

Staking~\cite{wolpert1992stacked} is a way to create a meta classifier using different base learners.
This method uses the prediction of different base learners as input for a meta leaner and combines them into a final decision.
Each base learner is trained on the training set and its prediction on the validation set is fet to the meta learner.
The test sample, in a similar way is first classified by the base learners and their prediction is passed through the meta learner in order to achieve the final decision.

 
